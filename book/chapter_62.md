// CHAPTER 62 ___________________________________________
// WHISPER (0x3E)

> СУТЬ:
УНИВЕРСАЛЬНОЕ УХО.
Модель от OpenAI, которая научилась слушать мир, просто
предсказывая следующий токен. State-of-the-Art в STT.

> ПОЧЕМУ ЭТО ВАЖНО (WHY IT MATTERS):
 1. Robustness: Работает в шуме, с эхом, с акцентами.
 2. Multilingual: Знает 99 языков и переводит на лету.
 3. Open Source: Вы можете запустить её на своем ноутбуке.

---

**ПОГРУЖЕНИЕ:**

До Whisper (2022) распознавание речи было сложным инженерным монстром. Нужны были словари фонем, акустические модели, языковые правила.
OpenAI пошли путем грубой силы. Они взяли 680,000 часов аудио из интернета и сказали Трансформеру:
"Вот спектрограмма звука. Вот текст субтитров. Учись находить связь".

Whisper — это **Sequence-to-Sequence** модель.
1. Encoder (зрение) смотрит на аудио-картинку и сжимает её в смыслы.
2. Decoder (язык) генерирует текст токен за токеном, как GPT.
Благодаря этому Whisper понимает контекст. Если он услышит неразборчивое "млоко", он напишет "молоко", потому что рядом было слово "корова".

```text
      AUDIO SPECTROGRAM
            |
            v
    [ ENCODER ] (Vision Transformer)
            |
      (Audio Embeddings)
            |
            v
    [ DECODER ] ---> <start> "Hello" "World" <eos>
    (LLM part)         (Autoregressive Generation)
```
