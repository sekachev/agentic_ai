// CHAPTER 26 ___________________________________________
// RAG (RETRIEVAL AUGMENTED GENERATION)

> СУТЬ:
ШПАРГАЛКА ДЛЯ ИИ.
Метод, позволяющий модели "подглядывать" в ваши документы
перед тем, как дать ответ.

> ПОЧЕМУ ЭТО ВАЖНО (WHY IT MATTERS):
 1. Приватность: Вы не дообучаете модель на своих данных. Вы просто даете ей почитать.
 2. Свежесть: Данные обновились? Просто обновите файл. Не нужно переучивать нейросеть.
 3. Экономия: Контекстное окно не бесконечное. RAG находит только нужные 2 абзаца из тысячи.

---

**ПОГРУЖЕНИЕ:**

Представьте, что вы сдаете экзамен по ядерной физике.
*   **Fine-Tuning (Дообучение):** Вы учите учебник наизусть год. Это долго и дорого.
*   **RAG (Поиск):** Вам разрешили принести учебник на экзамен. Вы открываете оглавление, находите нужную страницу, читаете и отвечаете.

В RAG главную роль играет **Векторный Поиск**. Текст превращается в цифры (эмбеддинги). "Собака" математически ближе к "Волку", чем к "Столу".

**Архитектура RAG:**

```text
    USER QUESTION
    "Как настроить VPN?"
          |
          v
    +-----------+
    | SEARCH TE | (Превращаем вопрос в вектор)
    +-----------+
          |
          v
    [ DATABASE ] <--- (Здесь лежат ваши инструкции,
    | |||||||| |       разрезанные на кусочки)
    '----------'
          |
          | (Находим 3 самых похожих кусочка)
          v
    +-----------------------------+
    | КОНТЕКСТ (Context)          |
    | 1. Зайдите в настройки...   |
    | 2. Нажмите Network...       |
    +-----------------------------+
          |
          v
    +-----------+
    |    LLM    | (Читает вопрос + найденный текст)
    +-----------+
          |
          v
    "Чтобы настроить VPN, зайдите в..."
```

**Ограничение:**
Если поиск (Retrieval) найдет мусор, LLM ответит мусором. Garbage In, Garbage Out. Качество RAG зависит от качества вашей базы знаний, а не от ума модели.
