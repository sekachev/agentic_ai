// CHAPTER 25 ___________________________________________
// ReAct PATTERN

> СУТЬ:
ВНУТРЕННИЙ МОНОЛОГ.
ReAct = Reasoning + Acting. Паттерн, заставляющий модель
"подумать вслух" перед каждым действием.

> ПОЧЕМУ ЭТО ВАЖНО (WHY IT MATTERS):
 1. Логика: Разбивает сложную задачу на шаги.
 2. Отладка: Вы видите "мысли" агента и понимаете, где он ошибся.
 3. Качество: Снижает галлюцинации, так как модель опирается
    на факты (Observations), а не на догадки.

---

**ПОГРУЖЕНИЕ:**

Обычная LLM работает в режиме "Вопрос -> Ответ".
ReAct-агент работает в цикле. Он ведет себя как детектив, который бормочет себе под нос.

**Цикл ReAct:**
1.  **Thought (Мысль):** "Пользователь хочет узнать погоду. Мне нужен инструмент WeatherAPI".
2.  **Action (Действие):** Вызов `WeatherAPI("Tallinn")`.
3.  **Observation (Наблюдение):** API вернул JSON `{temp: -5}`.
4.  **Thought (Мысль):** "Ага, холодно. Теперь сформирую ответ".
5.  **Final Answer (Ответ):** "В Таллинне -5 градусов".

Без этого цикла модель могла бы сразу выдать: "В Таллинне тепло", просто угадав наиболее вероятное продолжение текста.

```text
    ЗАДАЧА: "Кто жена президента Франции?"
       |
       v
  .---------.
  | THOUGHT | "Нужно найти имя президента Франции."
  '---------'
       |
       v
  .---------.      .-------------.
  | ACTION  | ---> | SEARCH:     |
  | (Search)|      | "France     |
  '---------'      |  President" |
       |           '-------------'
       |                  |
  .---------.             v
  | OBSERV  | <--- "Emmanuel Macron"
  '---------'
       |
       v
  .---------.
  | THOUGHT | "Теперь нужно найти жену Макрона."
  '---------'
       |
       v
  .---------.      .-------------.
  | ACTION  | ---> | SEARCH:     |
  | (Search)|      | "Macron     |
  '---------'      |  Wife"      |
       |           '-------------'
       |                  |
  .---------.             v
  | OBSERV  | <--- "Brigitte Macron"
  '---------'
       |
       v
  [ FINAL ANSWER: Brigitte Macron ]
```

**Цена интеллекта:**
ReAct требует больше токенов и времени. Агент делает 3-4 запроса к LLM вместо одного. Но результат того стоит.
